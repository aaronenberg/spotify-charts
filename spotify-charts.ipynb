{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSUS - CSc 177-02 Data Warehousing and Data Mining - Final Project:   \n",
    "### 2016 U.S. presidential election Twitter analysis  \n",
    "\n",
    "**Group members: Aaron Enberg, Nima Sarrafzadeh, Kyne Liu**  \n",
    "**Professor: Haiquan (Victor) Chen**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import (\n",
    "    preprocessing,  \n",
    "    cluster as sk_cluster,\n",
    "    metrics\n",
    ")\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.pipeline import make_pipeline, Pipeline\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from imblearn.under_sampling import (\n",
    "    RandomUnderSampler, \n",
    "    NearMiss, \n",
    "    EditedNearestNeighbours, \n",
    "    RepeatedEditedNearestNeighbours,\n",
    "    CondensedNearestNeighbour,\n",
    "    NeighbourhoodCleaningRule,\n",
    "    OneSidedSelection,\n",
    "    AllKNN,\n",
    "    TomekLinks\n",
    ")\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.ensemble import EasyEnsemble, BalanceCascade\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import (\n",
    "    cross_val_score,\n",
    "    train_test_split,\n",
    "    GridSearchCV,\n",
    "    StratifiedKFold\n",
    ")\n",
    "import sklearn.feature_extraction.text as sk_text\n",
    "import gc\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_spotify = pd.read_csv('./data/data.csv')\n",
    "daily_spotify.columns = ['position', 'track_name', 'artist', 'streams', 'url', 'date', 'region']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3441197, 7)\n",
      "position      int64 \n",
      "track_name    object\n",
      "artist        object\n",
      "streams       int64 \n",
      "url           object\n",
      "date          object\n",
      "region        object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(daily_spotify.shape)\n",
    "print(daily_spotify.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>position</th>\n",
       "      <th>track_name</th>\n",
       "      <th>artist</th>\n",
       "      <th>streams</th>\n",
       "      <th>url</th>\n",
       "      <th>date</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Reggaetón Lento (Bailemos)</td>\n",
       "      <td>CNCO</td>\n",
       "      <td>19272</td>\n",
       "      <td>https://open.spotify.com/track/3AEZUABDXNtecAOSC1qTfo</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>ec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Chantaje</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>19270</td>\n",
       "      <td>https://open.spotify.com/track/6mICuAdrwEjh6Y6lroV2Kg</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>ec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Otra Vez (feat. J Balvin)</td>\n",
       "      <td>Zion &amp; Lennox</td>\n",
       "      <td>15761</td>\n",
       "      <td>https://open.spotify.com/track/3QwBODjSEzelZyVjxPOHdq</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>ec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Vente Pa' Ca</td>\n",
       "      <td>Ricky Martin</td>\n",
       "      <td>14954</td>\n",
       "      <td>https://open.spotify.com/track/7DM4BPaS7uofFul3ywMe46</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>ec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Safari</td>\n",
       "      <td>J Balvin</td>\n",
       "      <td>14269</td>\n",
       "      <td>https://open.spotify.com/track/6rQSrBHf7HlZjtcMZ4S4bO</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>ec</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   position                  track_name         artist  streams  \\\n",
       "0  1         Reggaetón Lento (Bailemos)  CNCO           19272     \n",
       "1  2         Chantaje                    Shakira        19270     \n",
       "2  3         Otra Vez (feat. J Balvin)   Zion & Lennox  15761     \n",
       "3  4         Vente Pa' Ca                Ricky Martin   14954     \n",
       "4  5         Safari                      J Balvin       14269     \n",
       "\n",
       "                                                     url        date region  \n",
       "0  https://open.spotify.com/track/3AEZUABDXNtecAOSC1qTfo  2017-01-01  ec     \n",
       "1  https://open.spotify.com/track/6mICuAdrwEjh6Y6lroV2Kg  2017-01-01  ec     \n",
       "2  https://open.spotify.com/track/3QwBODjSEzelZyVjxPOHdq  2017-01-01  ec     \n",
       "3  https://open.spotify.com/track/7DM4BPaS7uofFul3ywMe46  2017-01-01  ec     \n",
       "4  https://open.spotify.com/track/6rQSrBHf7HlZjtcMZ4S4bO  2017-01-01  ec     "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_spotify.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ec', 'fr', 'ar', 'fi', 'no', 'it', 'lt', 'ph', 'tw', 'nz', 'ee',\n",
       "       'tr', 'us', 'sv', 'cr', 'de', 'cl', 'jp', 'br', 'hn', 'gt', 'ch',\n",
       "       'hu', 'ca', 'pe', 'be', 'my', 'dk', 'bo', 'pl', 'at', 'pt', 'se',\n",
       "       'mx', 'pa', 'uy', 'is', 'es', 'cz', 'ie', 'nl', 'sk', 'co', 'sg',\n",
       "       'id', 'do', 'lu', 'gb', 'global', 'py', 'au', 'lv', 'gr', 'hk'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_spotify['region'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_streams_by_country = daily_spotify.groupby(['track_name', 'artist', 'region', 'date', 'position'], as_index=False)['streams'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_name</th>\n",
       "      <th>artist</th>\n",
       "      <th>region</th>\n",
       "      <th>date</th>\n",
       "      <th>position</th>\n",
       "      <th>streams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"All That Is or Ever Was or Ever Will Be\"</td>\n",
       "      <td>Alan Silvestri</td>\n",
       "      <td>pl</td>\n",
       "      <td>2017-01-08</td>\n",
       "      <td>185</td>\n",
       "      <td>3547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"All That Is or Ever Was or Ever Will Be\"</td>\n",
       "      <td>Alan Silvestri</td>\n",
       "      <td>tr</td>\n",
       "      <td>2017-01-08</td>\n",
       "      <td>198</td>\n",
       "      <td>3764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Read All About It, Pt. III\"</td>\n",
       "      <td>Emeli Sandé</td>\n",
       "      <td>be</td>\n",
       "      <td>2017-10-09</td>\n",
       "      <td>186</td>\n",
       "      <td>3075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Read All About It, Pt. III\"</td>\n",
       "      <td>Emeli Sandé</td>\n",
       "      <td>be</td>\n",
       "      <td>2017-10-15</td>\n",
       "      <td>192</td>\n",
       "      <td>3053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Read All About It, Pt. III\"</td>\n",
       "      <td>Emeli Sandé</td>\n",
       "      <td>be</td>\n",
       "      <td>2017-10-16</td>\n",
       "      <td>147</td>\n",
       "      <td>3330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"Read All About It, Pt. III\"</td>\n",
       "      <td>Emeli Sandé</td>\n",
       "      <td>be</td>\n",
       "      <td>2017-10-22</td>\n",
       "      <td>182</td>\n",
       "      <td>3179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\"Read All About It, Pt. III\"</td>\n",
       "      <td>Emeli Sandé</td>\n",
       "      <td>be</td>\n",
       "      <td>2017-10-23</td>\n",
       "      <td>159</td>\n",
       "      <td>3334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\"Read All About It, Pt. III\"</td>\n",
       "      <td>Emeli Sandé</td>\n",
       "      <td>cz</td>\n",
       "      <td>2017-10-09</td>\n",
       "      <td>184</td>\n",
       "      <td>1338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\"Read All About It, Pt. III\"</td>\n",
       "      <td>Emeli Sandé</td>\n",
       "      <td>cz</td>\n",
       "      <td>2017-10-15</td>\n",
       "      <td>190</td>\n",
       "      <td>1222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\"Read All About It, Pt. III\"</td>\n",
       "      <td>Emeli Sandé</td>\n",
       "      <td>cz</td>\n",
       "      <td>2017-10-16</td>\n",
       "      <td>163</td>\n",
       "      <td>1527</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  track_name          artist region  \\\n",
       "0  \"All That Is or Ever Was or Ever Will Be\"  Alan Silvestri  pl      \n",
       "1  \"All That Is or Ever Was or Ever Will Be\"  Alan Silvestri  tr      \n",
       "2  \"Read All About It, Pt. III\"               Emeli Sandé     be      \n",
       "3  \"Read All About It, Pt. III\"               Emeli Sandé     be      \n",
       "4  \"Read All About It, Pt. III\"               Emeli Sandé     be      \n",
       "5  \"Read All About It, Pt. III\"               Emeli Sandé     be      \n",
       "6  \"Read All About It, Pt. III\"               Emeli Sandé     be      \n",
       "7  \"Read All About It, Pt. III\"               Emeli Sandé     cz      \n",
       "8  \"Read All About It, Pt. III\"               Emeli Sandé     cz      \n",
       "9  \"Read All About It, Pt. III\"               Emeli Sandé     cz      \n",
       "\n",
       "         date  position  streams  \n",
       "0  2017-01-08  185       3547     \n",
       "1  2017-01-08  198       3764     \n",
       "2  2017-10-09  186       3075     \n",
       "3  2017-10-15  192       3053     \n",
       "4  2017-10-16  147       3330     \n",
       "5  2017-10-22  182       3179     \n",
       "6  2017-10-23  159       3334     \n",
       "7  2017-10-09  184       1338     \n",
       "8  2017-10-15  190       1222     \n",
       "9  2017-10-16  163       1527     "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_streams_by_country.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the first day a song hits the top 200, which countries' charts does it appear on? \n",
    "df_country_initial_appear = df_streams_by_country.drop_duplicates(\n",
    "    ['track_name', 'artist', 'region'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_name</th>\n",
       "      <th>artist</th>\n",
       "      <th>region</th>\n",
       "      <th>date</th>\n",
       "      <th>position</th>\n",
       "      <th>streams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"All That Is or Ever Was or Ever Will Be\"</td>\n",
       "      <td>Alan Silvestri</td>\n",
       "      <td>pl</td>\n",
       "      <td>2017-01-08</td>\n",
       "      <td>185</td>\n",
       "      <td>3547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"All That Is or Ever Was or Ever Will Be\"</td>\n",
       "      <td>Alan Silvestri</td>\n",
       "      <td>tr</td>\n",
       "      <td>2017-01-08</td>\n",
       "      <td>198</td>\n",
       "      <td>3764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Read All About It, Pt. III\"</td>\n",
       "      <td>Emeli Sandé</td>\n",
       "      <td>be</td>\n",
       "      <td>2017-10-09</td>\n",
       "      <td>186</td>\n",
       "      <td>3075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\"Read All About It, Pt. III\"</td>\n",
       "      <td>Emeli Sandé</td>\n",
       "      <td>cz</td>\n",
       "      <td>2017-10-09</td>\n",
       "      <td>184</td>\n",
       "      <td>1338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>\"Read All About It, Pt. III\"</td>\n",
       "      <td>Emeli Sandé</td>\n",
       "      <td>dk</td>\n",
       "      <td>2017-02-12</td>\n",
       "      <td>188</td>\n",
       "      <td>6967</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   track_name          artist region  \\\n",
       "0   \"All That Is or Ever Was or Ever Will Be\"  Alan Silvestri  pl      \n",
       "1   \"All That Is or Ever Was or Ever Will Be\"  Alan Silvestri  tr      \n",
       "2   \"Read All About It, Pt. III\"               Emeli Sandé     be      \n",
       "7   \"Read All About It, Pt. III\"               Emeli Sandé     cz      \n",
       "12  \"Read All About It, Pt. III\"               Emeli Sandé     dk      \n",
       "\n",
       "          date  position  streams  \n",
       "0   2017-01-08  185       3547     \n",
       "1   2017-01-08  198       3764     \n",
       "2   2017-10-09  186       3075     \n",
       "7   2017-10-09  184       1338     \n",
       "12  2017-02-12  188       6967     "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_country_initial_appear.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_country_initial_appear = df_country_initial_appear.groupby(\n",
    "    ['track_name', 'artist', 'region']\n",
    ").date.min().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrameGroupBy' object has no attribute 'to_frame'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-c5cbc78beeba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_country_initial_appear\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'track_name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'artist'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.virtualenvs/CSc177/lib/python3.5/site-packages/pandas/core/groupby.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m         raise AttributeError(\"%r object has no attribute %r\" %\n\u001b[0;32m--> 676\u001b[0;31m                              (type(self).__name__, attr))\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mplot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproperty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGroupByPlot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrameGroupBy' object has no attribute 'to_frame'"
     ]
    }
   ],
   "source": [
    "df_country_initial_appear.reset_index().groupby(['track_name', 'artist', 'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the regions features\n",
    "df_country_initial_appear.unstack(['region'], fill_value=0).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_country_initial_appear.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instead of actual dates the song first appeared, just mark with 0 or 1\n",
    "df_country_initial_appear[df_country_initial_appear['date'] != 0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_streams_by_country.pivot_table(index=['track_name', 'artist'], columns='region', values='streams', aggfunc=sum, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(level=[0,1], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['track_name_by_artist'] = df.track_name.str.cat(df.artist, sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['track_name', 'artist'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_streams_by_country['top10'] = np.where(df_streams_by_country['position'] <= 10, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_streams_by_country['top10'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top10 = df_streams_by_country.drop_duplicates(['track_name', 'artist', 'top10'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top10 = df_top10.sort_values(['track_name', 'artist', 'top10'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top10.drop_duplicates(['track_name', 'artist'], keep='last', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top10['top10'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top10.reset_index(level=0, drop=True, inplace=True)\n",
    "df_top10.drop(['track_name', 'artist', 'region', 'position', 'date', 'streams'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top10.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = df.join(df_country_initial_appear.date.add_prefix('appear_'), how='inner')\n",
    "df_2.set_index('track_name_by_artist', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('track_name_by_artist', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_top10['top10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_scaler = preprocessing.StandardScaler()\n",
    "X_train_scaled = std_scaler.fit_transform(X_train)\n",
    "X_test_scaled = std_scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "# Create the samplers\n",
    "#enn = EditedNearestNeighbours()\n",
    "#renn = RepeatedEditedNearestNeighbours()\n",
    "ak = AllKNN(ratio='auto', kind_sel='mode', n_neighbors=3)\n",
    "#oss = OneSidedSelection()\n",
    "#ncr = NeighbourhoodCleaningRule()\n",
    "#nm = NearMiss()\n",
    "#rus = RandomUnderSampler()\n",
    "# Create the classifier\n",
    "k_range = list(range(1, 20))\n",
    "params = {'n_neighbors': k_range}\n",
    "\n",
    "''' weights='distance' weight points by the inverse of their distance. \n",
    "    in this case, closer neighbors of a query point will have a greater \n",
    "    influence than neighbors which are further away. \n",
    "    p=1 manhattan distance '''\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=1, weights='uniform', \n",
    "                           algorithm='auto', leaf_size=30, \n",
    "                           p=1, metric='minkowski', \n",
    "                           metric_params=None, n_jobs=1)\n",
    "\n",
    "knn_grid_search_cv = GridSearchCV(knn, params, \n",
    "                                  cv=5, n_jobs=-1, \n",
    "                                  verbose=1, \n",
    "                                  scoring='f1_weighted')\n",
    "\n",
    "# Add one transformers and two samplers in the pipeline object\n",
    "\n",
    "pipeline = make_pipeline(pca, ak, knn_grid_search_cv)\n",
    "\n",
    "pipeline.fit(X_train_scaled, y_train)\n",
    "y_pred = pipeline.predict(X_test_scaled)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cs = np.logspace(-5, 15, num=11, base=2.0)\n",
    "gammas = np.logspace(-15, 3, num=11, base=2.0)\n",
    "print(\"Tested Cs\", Cs)\n",
    "print(\"Tested gammas\", gammas)\n",
    "param_grid = {'C': Cs, 'gamma': gammas}\n",
    "\n",
    "# fit the model and get the separating hyperplane\n",
    "svm_grid_search_cv = GridSearchCV(SVC(kernel='rbf'), param_grid, scoring='f1_weighted', cv=10)\n",
    "\n",
    "# Add one transformers and two samplers in the pipeline object\n",
    "\n",
    "pipeline = make_pipeline(pca, ak, svm_grid_search_cv)\n",
    "\n",
    "pipeline.fit(X_train_scaled, y_train)\n",
    "y_pred = pipeline.predict(X_test_scaled)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_vis = pca.fit_transform(X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ak = AllKNN()\n",
    "X_resampled, y_resampled = ak.fit_sample(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_smote = LinearSVC().fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf_smote.predict(X_test_scaled)\n",
    "print(\"Support Vector Machine classification results\")\n",
    "print(\"\\n F1-Score \\n\", metrics.f1_score(y_test, y_pred))\n",
    "print(\"\\n Precision \\n\", metrics.precision_score(y_test, y_pred))\n",
    "print(\"\\n Recall \\n\", metrics.recall_score(y_test, y_pred))\n",
    "print(\"\\n Confusion Matrix \\n\", metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_clf = SVC(C=5, kernel='rbf', degree=3, \n",
    "              gamma=.005, coef0=0.0, shrinking=True, \n",
    "              probability=False, tol=0.001, cache_size=200, \n",
    "              class_weight={0: 1, 1: 2}, verbose=False, max_iter=-1, \n",
    "              decision_function_shape='ovr', random_state=42)\n",
    "svm_clf.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svm_clf.predict(X_test_scaled)\n",
    "print(\"Support Vector Machine classification results\")\n",
    "print(\"\\n F1-Score \\n\", metrics.f1_score(y_test, y_pred))\n",
    "print(\"\\n Precision \\n\", metrics.precision_score(y_test, y_pred))\n",
    "print(\"\\n Recall \\n\", metrics.recall_score(y_test, y_pred))\n",
    "print(\"\\n Confusion Matrix \\n\", metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_svm_clf = LinearSVC(penalty='l2', loss='squared_hinge', \n",
    "                           dual=True, tol=0.0001, C=1.0, \n",
    "                           multi_class='ovr', fit_intercept=True, \n",
    "                           intercept_scaling=1, class_weight=None, \n",
    "                           verbose=0, random_state=None, max_iter=1000)\n",
    "linear_svm_clf.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = linear_svm_clf.predict(X_test_scaled)\n",
    "print(\"Support Vector Machine classification results\")\n",
    "print(\"\\n F1-Score \\n\", metrics.f1_score(y_test, y_pred))\n",
    "print(\"\\n Precision \\n\", metrics.precision_score(y_test, y_pred))\n",
    "print(\"\\n Recall \\n\", metrics.recall_score(y_test, y_pred))\n",
    "print(\"\\n Confusion Matrix \\n\", metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_clf = DecisionTreeClassifier(criterion='entropy', \n",
    "                                  splitter='best', \n",
    "                                  max_depth=None, \n",
    "                                  min_samples_split=2, \n",
    "                                  min_samples_leaf=1, \n",
    "                                  min_weight_fraction_leaf=0.0, \n",
    "                                  max_features=None, \n",
    "                                  random_state=42, \n",
    "                                  max_leaf_nodes=23, \n",
    "                                  min_impurity_decrease=0.0, \n",
    "                                  min_impurity_split=None, \n",
    "                                  class_weight='balanced', \n",
    "                                  presort=False)\n",
    "tree_clf.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = tree_clf.predict(X_test_scaled)\n",
    "print(\"Decision Tree classification results\")\n",
    "print(\"\\n F1-Score \\n\", metrics.f1_score(y_test, y_pred))\n",
    "print(\"\\n Precision \\n\", metrics.precision_score(y_test, y_pred))\n",
    "print(\"\\n Recall \\n\", metrics.recall_score(y_test, y_pred))\n",
    "print(\"\\n Confusion Matrix \\n\", metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(penalty='l2', dual=False, \n",
    "                             tol=0.0001, C=.0094, \n",
    "                             fit_intercept=True, \n",
    "                             intercept_scaling=1, \n",
    "                             class_weight=None, \n",
    "                             random_state=42, \n",
    "                             solver='liblinear', \n",
    "                             max_iter=100, \n",
    "                             multi_class='ovr', \n",
    "                             verbose=0, \n",
    "                             warm_start=False, n_jobs=1)\n",
    "log_reg.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = log_reg.predict(X_test_scaled)\n",
    "print(\"Logistic Regression classification results\")\n",
    "print(\"\\n F1-Score \\n\", metrics.f1_score(y_test, y_pred))\n",
    "print(\"\\n Precision \\n\", metrics.precision_score(y_test, y_pred))\n",
    "print(\"\\n Recall \\n\", metrics.recall_score(y_test, y_pred))\n",
    "print(\"\\n Confusion Matrix \\n\", metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "k_range = list(range(1, 20))\n",
    "params = {'n_neighbors': k_range}\n",
    "\n",
    "''' weights='distance' weight points by the inverse of their distance. \n",
    "    in this case, closer neighbors of a query point will have a greater \n",
    "    influence than neighbors which are further away. \n",
    "    p=1 manhattan distance '''\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=1, weights='distance', \n",
    "                           algorithm='auto', leaf_size=30, \n",
    "                           p=1, metric='minkowski', \n",
    "                           metric_params=None, n_jobs=1)\n",
    "\n",
    "knn_grid_search_cv = GridSearchCV(knn, params, \n",
    "                                  cv=5, n_jobs=-1, \n",
    "                                  verbose=1, \n",
    "                                  scoring='f1_weighted')\n",
    "\n",
    "knn_grid_search_cv.fit(X_train_scaled, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = knn_grid_search_cv.cv_results_['mean_test_score']\n",
    "for mean, params in zip(means, knn_grid_search_cv.cv_results_['params']):\n",
    "    print(mean, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(k_range, means)\n",
    "plt.xlabel('Value of K for KNN')\n",
    "plt.ylabel('F1 score based on Cross-Validation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(knn_grid_search_cv.best_score_)\n",
    "print(knn_grid_search_cv.best_params_)\n",
    "print(knn_grid_search_cv.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn_grid_search_cv.predict(X_test_scaled)\n",
    "print(\"k-Nearest Neighbors classification results\")\n",
    "print(\"\\n F1-Score \\n\", metrics.f1_score(y_test, y_pred))\n",
    "print(\"\\n Precision \\n\", metrics.precision_score(y_test, y_pred))\n",
    "print(\"\\n Recall \\n\", metrics.recall_score(y_test, y_pred))\n",
    "print(\"\\n Confusion Matrix \\n\", metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(ratio='auto', random_state=None, \n",
    "           k=None, k_neighbors=5, m=None, \n",
    "           m_neighbors=10, out_step=0.5, \n",
    "           kind='regular', svm_estimator=None, \n",
    "           n_jobs=1)\n",
    "\n",
    "smote_enn = SMOTEENN(smote = sm)\n",
    "\n",
    "pipeline = make_pipeline(smote_enn, knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_neighbors': k_range}\n",
    "knn_grid_search_cv = GridSearchCV(pipeline, param_grid=params, \n",
    "                                  cv=5, n_jobs=-1, \n",
    "                                  verbose=1, \n",
    "                                  scoring='f1_weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_grid_search_cv.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=12, ratio = 1.0)\n",
    "x_train_res, y_train_res = sm.fit_sample(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rf = RandomForestClassifier(n_estimators=25, random_state=12)\n",
    "clf_rf.fit(x_train_res, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf_rf.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Random Forest classification results\")\n",
    "print(\"\\n F1-Score \\n\", metrics.f1_score(y_test, y_pred))\n",
    "print(\"\\n Precision \\n\", metrics.precision_score(y_test, y_pred))\n",
    "print(\"\\n Recall \\n\", metrics.recall_score(y_test, y_pred))\n",
    "print(\"\\n Confusion Matrix \\n\", metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('oversample', SMOTE(random_state=444)),\n",
    "    ('clf', knn)\n",
    "    ])\n",
    "\n",
    "skf = StratifiedKFold()\n",
    "param_grid = {'clf__n_neighbors': k_range}\n",
    "grid = GridSearchCV(pipe, param_grid, return_train_score=False,\n",
    "                    n_jobs=-1, scoring='roc_auc', cv=skf)\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid.best_score_)\n",
    "print(grid.best_params_)\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid.predict(X_test_scaled)\n",
    "print(\"k-Nearest Neighbors classification results\")\n",
    "print(\"\\n F1-Score \\n\", metrics.f1_score(y_test, y_pred))\n",
    "print(\"\\n Precision \\n\", metrics.precision_score(y_test, y_pred))\n",
    "print(\"\\n Recall \\n\", metrics.recall_score(y_test, y_pred))\n",
    "print(\"\\n Confusion Matrix \\n\", metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
